#  Multilingual RAG System 

This is a **Retrieval-Augmented Generation (RAG)** system capable of understanding user queries in **English and Bangla**  and generating grounded responses based on a document corpus. 

---

## ðŸ“Œ Features

- âœ… Document chunking and vector-based semantic search
- âœ… Query handling in English and Bangla
- âœ… Groq LLM integration using LLaMA3
- âœ… PDF-ready architecture
- âœ… Easily extensible REST API 

---

## âš™ï¸ Setup Guide

### 1. Clone the repository
```bash
git clone https://github.com/PritoM-Debnath/RAG.git
cd RAG
```

### 2. Create and activate virtual environment
```bash
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Set your API key
Create a `.env` file:
```env
GROQ_API_KEY=your-api-key-here
```

---

## ðŸ§° Dependencies

- `fastapi` / `uvicorn` â€” REST API
- `sentence-transformers` â€” Embedding model
- `faiss-cpu` â€” Vector search
- `groq` â€” Answer generation
- `pdfplumber` â€” PDF text extraction
- `nltk` â€” Sentence chunking
- `python-dotenv` â€” Environment variable support

---

## ðŸ”Ž Sample Query Flow

```python
response = rag_pipeline(
    query="What did the hero do after the battle?",
    story_path=r""  # your text dataset path 
)
print(response)
```

---

## ðŸ§ª Sample Queries & Outputs

| Language | Query                                     | Answer           |
|----------|-------------------------------------------|------------------|
| English  | Who has been called Anupam's goddess of fortune?    | Anupam's uncle has been called his goddess of fortune.|
| Bangla   | à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?       | à¦®à¦¾à¦®à¦¾à¦•à§‡            |


---

## ðŸ“‘ API Documentation 


### ðŸ› ï¸ Base URL
```
http://localhost:8000
```

---

### ðŸ” POST `/query`

**Request:**
```json
{
  "question": "à¦¹à¦°à¦¿à¦¶ à¦•à§‹à¦¥à¦¾à¦¯à¦¼ à¦•à¦¾à¦œ à¦•à¦°à§‡?"
}
```

**Response:**
```json
{
  "answer": "à¦•à¦¾à¦¨à¦ªà§à¦°à§‡"
}
```

Or:
```json
{
  "answer": "à¦¦à§à¦ƒà¦–à¦¿à¦¤, à¦ªà§à¦°à¦¾à¦¸à¦™à§à¦—à¦¿à¦• à¦¤à¦¥à§à¦¯ à¦–à§à¦à¦œà§‡ à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿à¥¤"
}
```

### Test with Swagger:
```
http://localhost:8000/docs
```

---


## ðŸ“ˆ Evaluation Matrix 

| Metric        | Method                                 |
|---------------|----------------------------------------|
| Groundedness  | Manual context overlap check           |
| Relevance     | Cosine similarity + human validation   |

---
## ðŸŽ†Workflow Diagram
![img.png](img.png)
## âœ… Q&A

### Q: What method or library did you use to extract the text, and why?
**A:**  used OCR and a combination of **pdfplumber**, **pytesseract**, and **Pillow** to extract text from the scanned Bangla PDF (HSC26-Bangla1st-Paper.pdf).

---

### Q: What chunking strategy did you choose?
**A:** Sentence-based chunking with a max word limit (500 words) using `nltk.sent_tokenize()`. This preserves semantic completeness and improves retrieval accuracy.

---

### Q: What embedding model did you use? Why?
**A:** `distiluse-base-multilingual-cased-v2` supports Bangla, additionally, 50+ languages`. Itâ€™s compact, fast, and delivers high-quality semantic embeddings suitable for small-scale RAG setups.

---

### Q: How are you comparing the query with your stored chunks?
**A:** Used FAISS for cosine similarity on embeddings. FAISS is efficient, production-ready, and scales well.

---

### Q: How do you ensure meaningful comparison between query and chunks?
**A:** Embeddings ensure semantic overlap. Prompt template ensures context injection before generation. For vague queries, the system still retrieves the closest relevant chunk.

---

### Q: Do the results seem relevant?
**A:** Yes, for most queries. However, results can be further improved by:
- Using multilingual embedding models (`distiluse-base-multilingual-cased-v2`)
- Fine-tuning chunk sizes
- Cleaning Bangla PDF more robustly

---

## ðŸ“‚ Directory Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ rag.py
â”‚   â””â”€â”€ retriever.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.txt
â”‚   â””â”€â”€ HSC26-Bangla1st-Paper.pdf
â”œâ”€â”€ api/
|    â”œâ”€â”€ main.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ sample_queries.py
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ” Security Note

API key is loaded from `.env` using `python-dotenv`. Make sure `.env` is added to `.gitignore`.

```bash
echo ".env" >> .gitignore
```

---

##  Future Work


- âœ… Multilingual embedding
- âœ… RAG evaluation module

---

## ðŸ“¬ Contact

For questions, contact: `debnathpritom@outlook.com`  

